{"version":3,"file":"chunks/lib-esnext_logic_operations_BuildPlanPlugin_js.js","mappings":";;;;;;;;;;;;;;;;;;AAAA;AACA;AAC+D;AACV;AACyB;AAC9E;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wCAAwC;AAC5D,oCAAoC,6DAAW;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,qCAAqC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,mFAAwB;AACxE;AACA;AACA;AACA;AACA,qBAAqB;AACrB,2DAA2D,qBAAqB;AAChF;AACA;AACA,YAAY,4EAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,sEAAsE,UAAU;AAChF,kEAAkE,SAAS;AAC3E,qDAAqD,yBAAyB;AAC9E;AACA;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA,2CAA2C,gBAAgB,MAAM,+BAA+B,YAAY,oBAAoB;AAChI;AACA;AACA,wCAAwC,uHAAuH;AAC/J;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kEAAkE;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,8BAA8B;AACtD;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wDAAwD,IAAI,oBAAoB,GAAG,oDAAoD;AACrK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,mIAAmI,GAAG,8EAA8E;AACzP;AACA;AACA;AACA,+BAA+B,gCAAgC;AAC/D;AACA;AACA;AACA,sCAAsC,aAAa;AACnD,8CAA8C,4DAA4D;AAC1G;AACA;AACA,oDAAoD;AACpD,iCAAiC,QAAQ,yGAAyG;AAClJ,8BAA8B,gBAAgB,eAAe,6DAA6D,KAAK,2IAA2I,KAAK;AAC/Q,4BAA4B;AAC5B;AACA,4CAA4C,6BAA6B,QAAQ,UAAU,WAAW,EAAE,qFAAqF,IAAI,aAAa;AAC9M;AACA;AACA;AACA;AACA","sources":["webpack://@microsoft/rush-lib/./lib-esnext/logic/operations/BuildPlanPlugin.js"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.\n// See LICENSE in the project root for license information.\nimport { clusterOperations } from './CacheableOperationPlugin';\nimport { DisjointSet } from '../cobuild/DisjointSet';\nimport { RushProjectConfiguration } from '../../api/RushProjectConfiguration';\nconst PLUGIN_NAME = 'BuildPlanPlugin';\nexport class BuildPlanPlugin {\n    constructor(terminal) {\n        this._terminal = terminal;\n    }\n    apply(hooks) {\n        const terminal = this._terminal;\n        hooks.beforeExecuteOperations.tap(PLUGIN_NAME, createBuildPlan);\n        function createBuildPlan(recordByOperation, context) {\n            const { projectConfigurations, inputsSnapshot } = context;\n            const disjointSet = new DisjointSet();\n            const operations = [...recordByOperation.keys()];\n            for (const operation of operations) {\n                disjointSet.add(operation);\n            }\n            const buildCacheByOperation = new Map();\n            for (const operation of operations) {\n                const { associatedProject, associatedPhase } = operation;\n                if (associatedProject && associatedPhase) {\n                    const projectConfiguration = projectConfigurations.get(associatedProject);\n                    const fileHashes = inputsSnapshot === null || inputsSnapshot === void 0 ? void 0 : inputsSnapshot.getTrackedFileHashesForOperation(associatedProject, associatedPhase.name);\n                    if (!fileHashes) {\n                        continue;\n                    }\n                    const cacheDisabledReason = RushProjectConfiguration.getCacheDisabledReasonForProject({\n                        projectConfiguration,\n                        trackedFileNames: fileHashes.keys(),\n                        isNoOp: operation.isNoOp,\n                        phaseName: associatedPhase.name\n                    });\n                    buildCacheByOperation.set(operation, { cacheDisabledReason });\n                }\n            }\n            clusterOperations(disjointSet, buildCacheByOperation);\n            const buildPlan = createCobuildPlan(disjointSet, terminal, buildCacheByOperation);\n            logCobuildBuildPlan(buildPlan, terminal);\n        }\n    }\n}\n/**\n * Output the build plan summary, this will include the depth of the build plan, the width of the build plan, and\n * the number of nodes at each depth.\n *\n * Example output:\n```\nBuild Plan Depth (deepest dependency tree): 3\nBuild Plan Width (maximum parallelism): 7\nNumber of Nodes per Depth: 2, 7, 5\nPlan @ Depth 0 has 2 nodes and 0 dependents:\n- b (build)\n- a (build)\nPlan @ Depth 1 has 7 nodes and 2 dependents:\n- c (build)\n- d (build)\n- f (pre-build)\n- g (pre-build)\n- e (build)\n- f (build)\n- g (build)\nPlan @ Depth 2 has 5 nodes and 9 dependents:\n- c (build)\n- d (build)\n- e (build)\n- f (build)\n- g (build)\n```\n * The summary data can be useful for understanding the shape of the build plan. The depth of the build plan is the\n *  longest dependency chain in the build plan. The width of the build plan is the maximum number of operations that\n *  can be executed in parallel. The number of nodes per depth is the number of operations that can be executed in parallel\n *  at each depth. **This does not currently include clustering information, which further restricts which operations can\n *  be executed in parallel.**\n * The depth data can be useful for debugging situations where cobuilds aren't utilizing multiple agents as expected. There may be\n *  some long dependency trees that can't be executed in parallel. Or there may be some key operations at the base of the\n *  build graph that are blocking the rest of the build.\n */\nfunction generateCobuildPlanSummary(operations, terminal) {\n    var _a, _b, _c, _d, _e;\n    const numberOfDependenciesByOperation = new Map();\n    const queue = operations.filter((e) => e.dependencies.size === 0);\n    const seen = new Set(queue);\n    for (const operation of queue) {\n        numberOfDependenciesByOperation.set(operation, 0);\n    }\n    /**\n     * Traverse the build plan to determine the number of dependencies for each operation. This is done by starting\n     *  at the base of the build plan and traversing the graph in a breadth-first manner. We use the parent operation\n     *  to determine the number of dependencies for each child operation. This allows us to detect cases where no-op\n     *  operations are strung together, and correctly mark the first real operation as being a root operation.\n     */\n    while (queue.length > 0) {\n        const operation = queue.shift();\n        const increment = operation.isNoOp ? 0 : 1;\n        for (const consumer of operation.consumers) {\n            const numberOfDependencies = ((_a = numberOfDependenciesByOperation.get(operation)) !== null && _a !== void 0 ? _a : 0) + increment;\n            numberOfDependenciesByOperation.set(consumer, numberOfDependencies);\n            if (!seen.has(consumer)) {\n                queue.push(consumer);\n                seen.add(consumer);\n            }\n        }\n    }\n    const layerQueue = [];\n    for (const operation of operations) {\n        if (operation.isNoOp) {\n            continue;\n        }\n        const numberOfDependencies = (_b = numberOfDependenciesByOperation.get(operation)) !== null && _b !== void 0 ? _b : 0;\n        if (numberOfDependencies === 0) {\n            layerQueue.push(operation);\n        }\n    }\n    let nextLayer = new Set();\n    const remainingOperations = new Set(operations);\n    let depth = 0;\n    let maxWidth = layerQueue.length;\n    const numberOfNodes = [maxWidth];\n    const depthToOperationsMap = new Map();\n    depthToOperationsMap.set(depth, new Set(layerQueue));\n    /**\n     * Determine the depth and width of the build plan. We start with the inner layer and gradually traverse layer by\n     *  layer up the tree/graph until we have no more nodes to process. At each layer, we determine the\n     *  number of executable operations.\n     */\n    do {\n        if (layerQueue.length === 0) {\n            layerQueue.push(...nextLayer);\n            const realOperations = layerQueue.filter((e) => !e.isNoOp);\n            if (realOperations.length > 0) {\n                depth += 1;\n                depthToOperationsMap.set(depth, new Set(realOperations));\n                numberOfNodes.push(realOperations.length);\n            }\n            const currentWidth = realOperations.length;\n            if (currentWidth > maxWidth) {\n                maxWidth = currentWidth;\n            }\n            nextLayer = new Set();\n            if (layerQueue.length === 0) {\n                break;\n            }\n        }\n        const leaf = layerQueue.shift();\n        if (remainingOperations.delete(leaf)) {\n            for (const consumer of leaf.consumers) {\n                nextLayer.add(consumer);\n            }\n        }\n    } while (remainingOperations.size > 0);\n    terminal.writeLine(`Build Plan Depth (deepest dependency tree): ${depth + 1}`);\n    terminal.writeLine(`Build Plan Width (maximum parallelism): ${maxWidth}`);\n    terminal.writeLine(`Number of Nodes per Depth: ${numberOfNodes.join(', ')}`);\n    for (const [operationDepth, operationsAtDepth] of depthToOperationsMap) {\n        let numberOfDependents = 0;\n        for (let i = 0; i < operationDepth; i++) {\n            numberOfDependents += numberOfNodes[i];\n        }\n        terminal.writeLine(`Plan @ Depth ${operationDepth} has ${numberOfNodes[operationDepth]} nodes and ${numberOfDependents} dependents:`);\n        for (const operation of operationsAtDepth) {\n            if (!((_c = operation.runner) === null || _c === void 0 ? void 0 : _c.isNoOp)) {\n                terminal.writeLine(`- ${(_e = (_d = operation.runner) === null || _d === void 0 ? void 0 : _d.name) !== null && _e !== void 0 ? _e : 'unknown'}`);\n            }\n        }\n    }\n    return {\n        maxDepth: depth === 0 && numberOfNodes[0] !== 0 ? depth + 1 : 0,\n        maxWidth: maxWidth,\n        numberOfNodesPerDepth: numberOfNodes\n    };\n}\nfunction getName(op) {\n    var _a, _b;\n    return (_b = (_a = op.runner) === null || _a === void 0 ? void 0 : _a.name) !== null && _b !== void 0 ? _b : 'unknown';\n}\n/**\n * Log the cobuild build plan by cluster. This is intended to help debug situations where cobuilds aren't\n *  utilizing multiple agents correctly.\n */\nfunction createCobuildPlan(disjointSet, terminal, buildCacheByOperation) {\n    const clusters = [...disjointSet.getAllSets()];\n    const operations = clusters.flatMap((e) => Array.from(e));\n    const operationToClusterMap = new Map();\n    for (const cluster of clusters) {\n        for (const operation of cluster) {\n            operationToClusterMap.set(operation, cluster);\n        }\n    }\n    return {\n        summary: generateCobuildPlanSummary(operations, terminal),\n        operations,\n        buildCacheByOperation,\n        clusterByOperation: operationToClusterMap,\n        clusters\n    };\n}\n/**\n * This method logs in depth details about the cobuild plan, including the operations in each cluster, the dependencies\n *  for each cluster, and the reason why each operation is clustered.\n */\nfunction logCobuildBuildPlan(buildPlan, terminal) {\n    var _a;\n    const { operations, clusters, buildCacheByOperation, clusterByOperation } = buildPlan;\n    const executionPlan = [];\n    for (const operation of operations) {\n        if (!operation.isNoOp) {\n            executionPlan.push(operation);\n        }\n    }\n    // This is a lazy way of getting the waterfall chart, basically check for the latest\n    //  dependency and put this operation after that finishes.\n    const spacingByDependencyMap = new Map();\n    for (let index = 0; index < executionPlan.length; index++) {\n        const operation = executionPlan[index];\n        const spacing = Math.max(...Array.from(operation.dependencies, (e) => {\n            const dependencySpacing = spacingByDependencyMap.get(e);\n            return dependencySpacing !== undefined ? dependencySpacing + 1 : 0;\n        }), 0);\n        spacingByDependencyMap.set(operation, spacing);\n    }\n    executionPlan.sort((a, b) => {\n        var _a, _b;\n        const aSpacing = (_a = spacingByDependencyMap.get(a)) !== null && _a !== void 0 ? _a : 0;\n        const bSpacing = (_b = spacingByDependencyMap.get(b)) !== null && _b !== void 0 ? _b : 0;\n        return aSpacing - bSpacing;\n    });\n    terminal.writeLine('##################################################');\n    // Get the maximum name length for left padding.\n    let maxOperationNameLength = 1;\n    for (const operation of executionPlan) {\n        const name = getName(operation);\n        maxOperationNameLength = Math.max(maxOperationNameLength, name.length);\n    }\n    for (const operation of executionPlan) {\n        const spacing = (_a = spacingByDependencyMap.get(operation)) !== null && _a !== void 0 ? _a : 0;\n        terminal.writeLine(`${getName(operation).padStart(maxOperationNameLength + 1)}: ${'-'.repeat(spacing)}(${clusters.indexOf(clusterByOperation.get(operation))})`);\n    }\n    terminal.writeLine('##################################################');\n    function getDependenciesForCluster(cluster) {\n        const dependencies = new Set();\n        for (const operation of cluster) {\n            for (const dependent of operation.dependencies) {\n                dependencies.add(dependent);\n            }\n        }\n        return dependencies;\n    }\n    function dedupeShards(ops) {\n        var _a, _b, _c;\n        const dedupedOperations = new Set();\n        for (const operation of ops) {\n            dedupedOperations.add(`${(_b = (_a = operation.associatedProject) === null || _a === void 0 ? void 0 : _a.packageName) !== null && _b !== void 0 ? _b : ''} (${(_c = operation.associatedPhase) === null || _c === void 0 ? void 0 : _c.name})`);\n        }\n        return [...dedupedOperations];\n    }\n    for (let clusterIndex = 0; clusterIndex < clusters.length; clusterIndex++) {\n        const cluster = clusters[clusterIndex];\n        const allClusterDependencies = getDependenciesForCluster(cluster);\n        const outOfClusterDependencies = new Set([...allClusterDependencies].filter((e) => !cluster.has(e)));\n        terminal.writeLine(`Cluster ${clusterIndex}:`);\n        terminal.writeLine(`- Dependencies: ${dedupeShards(outOfClusterDependencies).join(', ') || 'none'}`);\n        // Only log clustering info, if we did in fact cluster.\n        if (cluster.size > 1) {\n            terminal.writeLine(`- Clustered by: \\n${[...allClusterDependencies]\n                .filter((e) => { var _a; return (_a = buildCacheByOperation.get(e)) === null || _a === void 0 ? void 0 : _a.cacheDisabledReason; })\n                .map((e) => { var _a, _b, _c; return `  - (${(_a = e.runner) === null || _a === void 0 ? void 0 : _a.name}) \"${(_c = (_b = buildCacheByOperation.get(e)) === null || _b === void 0 ? void 0 : _b.cacheDisabledReason) !== null && _c !== void 0 ? _c : ''}\"`; })\n                .join('\\n')}`);\n        }\n        terminal.writeLine(`- Operations: ${Array.from(cluster, (e) => { var _a; return `${getName(e)}${((_a = e.runner) === null || _a === void 0 ? void 0 : _a.isNoOp) ? ' [SKIPPED]' : ''}`; }).join(', ')}`);\n        terminal.writeLine('--------------------------------------------------');\n    }\n    terminal.writeLine('##################################################');\n}\n//# sourceMappingURL=BuildPlanPlugin.js.map"],"names":[],"sourceRoot":""}