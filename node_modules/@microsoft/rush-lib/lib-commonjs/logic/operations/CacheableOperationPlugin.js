"use strict";
// Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT license.
// See LICENSE in the project root for license information.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.clusterOperations = exports.CacheableOperationPlugin = void 0;
const crypto = __importStar(require("crypto"));
const node_core_library_1 = require("@rushstack/node-core-library");
const stream_collator_1 = require("@rushstack/stream-collator");
const terminal_1 = require("@rushstack/terminal");
const terminal_2 = require("@rushstack/terminal");
const CollatedTerminalProvider_1 = require("../../utilities/CollatedTerminalProvider");
const OperationStatus_1 = require("./OperationStatus");
const CobuildLock_1 = require("../cobuild/CobuildLock");
const ProjectBuildCache_1 = require("../buildCache/ProjectBuildCache");
const RushConstants_1 = require("../RushConstants");
const ProjectLogWritable_1 = require("./ProjectLogWritable");
const DisjointSet_1 = require("../cobuild/DisjointSet");
const PeriodicCallback_1 = require("./PeriodicCallback");
const NullTerminalProvider_1 = require("../../utilities/NullTerminalProvider");
const PLUGIN_NAME = 'CacheablePhasedOperationPlugin';
const PERIODIC_CALLBACK_INTERVAL_IN_SECONDS = 10;
class CacheableOperationPlugin {
    constructor(options) {
        this._buildCacheContextByOperation = new Map();
        this._options = options;
    }
    apply(hooks) {
        const { allowWarningsInSuccessfulBuild, buildCacheConfiguration, cobuildConfiguration } = this._options;
        hooks.beforeExecuteOperations.tap(PLUGIN_NAME, (recordByOperation, context) => {
            var _a;
            const { isIncrementalBuildAllowed, inputsSnapshot, projectConfigurations, isInitial } = context;
            if (!inputsSnapshot) {
                throw new Error(`Build cache is only supported if running in a Git repository. Either disable the build cache or run Rush in a Git repository.`);
            }
            const disjointSet = (cobuildConfiguration === null || cobuildConfiguration === void 0 ? void 0 : cobuildConfiguration.cobuildFeatureEnabled)
                ? new DisjointSet_1.DisjointSet()
                : undefined;
            for (const [operation, record] of recordByOperation) {
                const stateHash = record.calculateStateHash({
                    inputsSnapshot,
                    buildCacheConfiguration
                });
                const { associatedProject, associatedPhase, runner, settings: operationSettings } = operation;
                if (!associatedProject || !associatedPhase || !runner) {
                    return;
                }
                const { name: phaseName } = associatedPhase;
                const projectConfiguration = projectConfigurations.get(associatedProject);
                // This value can *currently* be cached per-project, but in the future the list of files will vary
                // depending on the selected phase.
                const fileHashes = inputsSnapshot.getTrackedFileHashesForOperation(associatedProject, phaseName);
                const cacheDisabledReason = projectConfiguration
                    ? projectConfiguration.getCacheDisabledReason(fileHashes.keys(), phaseName, operation.isNoOp)
                    : `Project does not have a ${RushConstants_1.RushConstants.rushProjectConfigFilename} configuration file, ` +
                        'or one provided by a rig, so it does not support caching.';
                const metadataFolderPath = record.metadataFolderPath;
                const outputFolderNames = metadataFolderPath ? [metadataFolderPath] : [];
                const configuredOutputFolderNames = operationSettings === null || operationSettings === void 0 ? void 0 : operationSettings.outputFolderNames;
                if (configuredOutputFolderNames) {
                    for (const folderName of configuredOutputFolderNames) {
                        outputFolderNames.push(folderName);
                    }
                }
                disjointSet === null || disjointSet === void 0 ? void 0 : disjointSet.add(operation);
                const buildCacheContext = {
                    // Supports cache writes by default for initial operations.
                    // Don't write during watch runs for performance reasons (and to avoid flooding the cache)
                    isCacheWriteAllowed: isInitial,
                    isCacheReadAllowed: isIncrementalBuildAllowed,
                    operationBuildCache: undefined,
                    outputFolderNames,
                    stateHash,
                    cacheDisabledReason,
                    cobuildLock: undefined,
                    cobuildClusterId: undefined,
                    buildCacheTerminal: undefined,
                    buildCacheTerminalWritable: undefined,
                    periodicCallback: new PeriodicCallback_1.PeriodicCallback({
                        interval: PERIODIC_CALLBACK_INTERVAL_IN_SECONDS * 1000
                    }),
                    cacheRestored: false,
                    isCacheReadAttempted: false
                };
                // Upstream runners may mutate the property of build cache context for downstream runners
                this._buildCacheContextByOperation.set(operation, buildCacheContext);
            }
            if (disjointSet) {
                clusterOperations(disjointSet, this._buildCacheContextByOperation);
                for (const operationSet of disjointSet.getAllSets()) {
                    if ((cobuildConfiguration === null || cobuildConfiguration === void 0 ? void 0 : cobuildConfiguration.cobuildFeatureEnabled) && cobuildConfiguration.cobuildContextId) {
                        // Get a deterministic ordered array of operations, which is important to get a deterministic cluster id.
                        const groupedOperations = Array.from(operationSet);
                        node_core_library_1.Sort.sortBy(groupedOperations, (operation) => {
                            return operation.name;
                        });
                        // Generates cluster id, cluster id comes from the project folder and operation name of all operations in the same cluster.
                        const hash = crypto.createHash('sha1');
                        for (const operation of groupedOperations) {
                            const { associatedPhase: phase, associatedProject: project } = operation;
                            if (project && phase) {
                                hash.update(project.projectRelativeFolder);
                                hash.update(RushConstants_1.RushConstants.hashDelimiter);
                                hash.update((_a = operation.name) !== null && _a !== void 0 ? _a : phase.name);
                                hash.update(RushConstants_1.RushConstants.hashDelimiter);
                            }
                        }
                        const cobuildClusterId = hash.digest('hex');
                        // Assign same cluster id to all operations in the same cluster.
                        for (const record of groupedOperations) {
                            const buildCacheContext = this._getBuildCacheContextByOperationOrThrow(record);
                            buildCacheContext.cobuildClusterId = cobuildClusterId;
                        }
                    }
                }
            }
        });
        hooks.beforeExecuteOperation.tapPromise(PLUGIN_NAME, async (runnerContext) => {
            if (this._buildCacheContextByOperation.size === 0) {
                return;
            }
            const buildCacheContext = this._getBuildCacheContextByOperation(runnerContext.operation);
            if (!buildCacheContext) {
                return;
            }
            const record = runnerContext;
            const { associatedProject: project, associatedPhase: phase, runner, _operationMetadataManager: operationMetadataManager, operation } = record;
            if (!operation.enabled ||
                !project ||
                !phase ||
                !(runner === null || runner === void 0 ? void 0 : runner.cacheable) ||
                // this check is just to make the types happy, it will always be defined if project + phase are defined.
                !operationMetadataManager) {
                return;
            }
            const runBeforeExecute = async () => {
                var _a, _b;
                if (!buildCacheContext.buildCacheTerminal ||
                    ((_a = buildCacheContext.buildCacheTerminalWritable) === null || _a === void 0 ? void 0 : _a.isOpen) === false) {
                    // The writable does not exist or has been closed, re-create one
                    // eslint-disable-next-line require-atomic-updates
                    buildCacheContext.buildCacheTerminal = await this._createBuildCacheTerminalAsync({
                        record,
                        buildCacheContext,
                        buildCacheEnabled: buildCacheConfiguration === null || buildCacheConfiguration === void 0 ? void 0 : buildCacheConfiguration.buildCacheEnabled,
                        rushProject: project,
                        logFilenameIdentifier: operation.logFilenameIdentifier,
                        quietMode: record.quietMode,
                        debugMode: record.debugMode
                    });
                }
                const buildCacheTerminal = buildCacheContext.buildCacheTerminal;
                let projectBuildCache = this._tryGetProjectBuildCache({
                    buildCacheContext,
                    buildCacheConfiguration,
                    terminal: buildCacheTerminal,
                    record
                });
                // Try to acquire the cobuild lock
                let cobuildLock;
                if (cobuildConfiguration === null || cobuildConfiguration === void 0 ? void 0 : cobuildConfiguration.cobuildFeatureEnabled) {
                    if ((cobuildConfiguration === null || cobuildConfiguration === void 0 ? void 0 : cobuildConfiguration.cobuildLeafProjectLogOnlyAllowed) &&
                        operation.consumers.size === 0 &&
                        !projectBuildCache) {
                        // When the leaf project log only is allowed and the leaf project is build cache "disabled", try to get
                        // a log files only project build cache
                        projectBuildCache = await this._tryGetLogOnlyProjectBuildCacheAsync({
                            buildCacheConfiguration,
                            cobuildConfiguration,
                            buildCacheContext,
                            rushProject: project,
                            phase,
                            terminal: buildCacheTerminal
                        });
                        if (projectBuildCache) {
                            buildCacheTerminal.writeVerboseLine(`Log files only build cache is enabled for the project "${project.packageName}" because the cobuild leaf project log only is allowed`);
                        }
                        else {
                            buildCacheTerminal.writeWarningLine(`Failed to get log files only build cache for the project "${project.packageName}"`);
                        }
                    }
                    cobuildLock = await this._tryGetCobuildLockAsync({
                        buildCacheContext,
                        projectBuildCache,
                        cobuildConfiguration,
                        packageName: project.packageName,
                        phaseName: phase.name
                    });
                }
                // eslint-disable-next-line require-atomic-updates -- we are mutating the build cache context intentionally
                buildCacheContext.cobuildLock = cobuildLock;
                // If possible, we want to skip this operation -- either by restoring it from the
                // cache, if caching is enabled, or determining that the project
                // is unchanged (using the older incremental execution logic). These two approaches,
                // "caching" and "skipping", are incompatible, so only one applies.
                //
                // Note that "caching" and "skipping" take two different approaches
                // to tracking dependents:
                //
                //   - For caching, "isCacheReadAllowed" is set if a project supports
                //     incremental builds, and determining whether this project or a dependent
                //     has changed happens inside the hashing logic.
                //
                const { error: errorLogPath } = (0, ProjectLogWritable_1.getProjectLogFilePaths)({
                    project,
                    logFilenameIdentifier: operation.logFilenameIdentifier
                });
                const restoreCacheAsync = async (
                // TODO: Investigate if `projectBuildCacheForRestore` is always the same instance as `projectBuildCache`
                // above, and if it is, remove this parameter
                projectBuildCacheForRestore, specifiedCacheId) => {
                    buildCacheContext.isCacheReadAttempted = true;
                    const restoreFromCacheSuccess = await (projectBuildCacheForRestore === null || projectBuildCacheForRestore === void 0 ? void 0 : projectBuildCacheForRestore.tryRestoreFromCacheAsync(buildCacheTerminal, specifiedCacheId));
                    if (restoreFromCacheSuccess) {
                        buildCacheContext.cacheRestored = true;
                        await runnerContext.runWithTerminalAsync(async (taskTerminal, terminalProvider) => {
                            // Restore the original state of the operation without cache
                            await (operationMetadataManager === null || operationMetadataManager === void 0 ? void 0 : operationMetadataManager.tryRestoreAsync({
                                terminalProvider,
                                terminal: buildCacheTerminal,
                                errorLogPath
                            }));
                        }, { createLogFile: false });
                    }
                    return !!restoreFromCacheSuccess;
                };
                if (cobuildLock) {
                    // handling rebuilds. "rush rebuild" or "rush retest" command will save operations to
                    // the build cache once completed, but does not retrieve them (since the "incremental"
                    // flag is disabled). However, we still need a cobuild to be able to retrieve a finished
                    // build from another cobuild in this case.
                    const cobuildCompletedState = await cobuildLock.getCompletedStateAsync();
                    if (cobuildCompletedState) {
                        const { status, cacheId } = cobuildCompletedState;
                        if ((_b = record.operation.settings) === null || _b === void 0 ? void 0 : _b.allowCobuildWithoutCache) {
                            // This should only be enabled if the experiment for cobuild orchestration is enabled.
                            return status;
                        }
                        const restoreFromCacheSuccess = await restoreCacheAsync(cobuildLock.projectBuildCache, cacheId);
                        if (restoreFromCacheSuccess) {
                            return status;
                        }
                    }
                    else if (!buildCacheContext.isCacheReadAttempted && buildCacheContext.isCacheReadAllowed) {
                        const restoreFromCacheSuccess = await restoreCacheAsync(projectBuildCache);
                        if (restoreFromCacheSuccess) {
                            return OperationStatus_1.OperationStatus.FromCache;
                        }
                    }
                }
                else if (buildCacheContext.isCacheReadAllowed) {
                    const restoreFromCacheSuccess = await restoreCacheAsync(projectBuildCache);
                    if (restoreFromCacheSuccess) {
                        return OperationStatus_1.OperationStatus.FromCache;
                    }
                }
                if (buildCacheContext.isCacheWriteAllowed && cobuildLock) {
                    const acquireSuccess = await cobuildLock.tryAcquireLockAsync();
                    if (acquireSuccess) {
                        const { periodicCallback } = buildCacheContext;
                        periodicCallback.addCallback(async () => {
                            await (cobuildLock === null || cobuildLock === void 0 ? void 0 : cobuildLock.renewLockAsync());
                        });
                        periodicCallback.start();
                    }
                    else {
                        setTimeout(() => {
                            record.status = OperationStatus_1.OperationStatus.Ready;
                        }, 500);
                        return OperationStatus_1.OperationStatus.Executing;
                    }
                }
            };
            return await runBeforeExecute();
        });
        hooks.afterExecuteOperation.tapPromise(PLUGIN_NAME, async (runnerContext) => {
            var _a;
            const record = runnerContext;
            const { status, stopwatch, _operationMetadataManager: operationMetadataManager, operation } = record;
            const { associatedProject: project, associatedPhase: phase, runner, enabled } = operation;
            if (!enabled || !project || !phase || !(runner === null || runner === void 0 ? void 0 : runner.cacheable) || !operationMetadataManager) {
                return;
            }
            const buildCacheContext = this._getBuildCacheContextByOperation(operation);
            if (!buildCacheContext) {
                return;
            }
            // No need to run for the following operation status
            if (!record.isTerminal || record.status === OperationStatus_1.OperationStatus.NoOp) {
                return;
            }
            const { cobuildLock, operationBuildCache, isCacheWriteAllowed, buildCacheTerminal, cacheRestored } = buildCacheContext;
            try {
                if (!cacheRestored) {
                    // Save the metadata to disk
                    const { logFilenameIdentifier } = operationMetadataManager;
                    const { duration: durationInSeconds } = stopwatch;
                    const { text: logPath, error: errorLogPath, jsonl: logChunksPath } = (0, ProjectLogWritable_1.getProjectLogFilePaths)({
                        project,
                        logFilenameIdentifier
                    });
                    await operationMetadataManager.saveAsync({
                        durationInSeconds,
                        cobuildContextId: cobuildLock === null || cobuildLock === void 0 ? void 0 : cobuildLock.cobuildConfiguration.cobuildContextId,
                        cobuildRunnerId: cobuildLock === null || cobuildLock === void 0 ? void 0 : cobuildLock.cobuildConfiguration.cobuildRunnerId,
                        logPath,
                        errorLogPath,
                        logChunksPath
                    });
                }
                if (!buildCacheTerminal) {
                    // This should not happen
                    throw new node_core_library_1.InternalError(`Build Cache Terminal is not created`);
                }
                let setCompletedStatePromiseFunction;
                let setCacheEntryPromise;
                if (cobuildLock && isCacheWriteAllowed) {
                    const { cacheId, contextId } = cobuildLock.cobuildContext;
                    let finalCacheId = cacheId;
                    if (status === OperationStatus_1.OperationStatus.Failure) {
                        finalCacheId = `${cacheId}-${contextId}-failed`;
                    }
                    else if (status === OperationStatus_1.OperationStatus.SuccessWithWarning && !record.runner.warningsAreAllowed) {
                        finalCacheId = `${cacheId}-${contextId}-warnings`;
                    }
                    switch (status) {
                        case OperationStatus_1.OperationStatus.SuccessWithWarning:
                        case OperationStatus_1.OperationStatus.Success:
                        case OperationStatus_1.OperationStatus.Failure: {
                            const currentStatus = status;
                            setCompletedStatePromiseFunction = () => {
                                return cobuildLock === null || cobuildLock === void 0 ? void 0 : cobuildLock.setCompletedStateAsync({
                                    status: currentStatus,
                                    cacheId: finalCacheId
                                });
                            };
                            setCacheEntryPromise = () => cobuildLock.projectBuildCache.trySetCacheEntryAsync(buildCacheTerminal, finalCacheId);
                        }
                    }
                }
                const taskIsSuccessful = status === OperationStatus_1.OperationStatus.Success ||
                    (status === OperationStatus_1.OperationStatus.SuccessWithWarning &&
                        record.runner.warningsAreAllowed &&
                        allowWarningsInSuccessfulBuild);
                // If the command is successful, we can calculate project hash, and no dependencies were skipped,
                // write a new cache entry.
                if (!setCacheEntryPromise && taskIsSuccessful && isCacheWriteAllowed && operationBuildCache) {
                    setCacheEntryPromise = () => operationBuildCache.trySetCacheEntryAsync(buildCacheTerminal);
                }
                if (!cacheRestored) {
                    const cacheWriteSuccess = await (setCacheEntryPromise === null || setCacheEntryPromise === void 0 ? void 0 : setCacheEntryPromise());
                    await (setCompletedStatePromiseFunction === null || setCompletedStatePromiseFunction === void 0 ? void 0 : setCompletedStatePromiseFunction());
                    if (cacheWriteSuccess === false && status === OperationStatus_1.OperationStatus.Success) {
                        record.status = OperationStatus_1.OperationStatus.SuccessWithWarning;
                    }
                }
            }
            finally {
                (_a = buildCacheContext.buildCacheTerminalWritable) === null || _a === void 0 ? void 0 : _a.close();
                buildCacheContext.periodicCallback.stop();
            }
        });
        hooks.afterExecuteOperation.tap(PLUGIN_NAME, (record) => {
            const { operation } = record;
            const buildCacheContext = this._buildCacheContextByOperation.get(operation);
            // Status changes to direct dependents
            let blockCacheWrite = !(buildCacheContext === null || buildCacheContext === void 0 ? void 0 : buildCacheContext.isCacheWriteAllowed);
            switch (record.status) {
                case OperationStatus_1.OperationStatus.Skipped: {
                    // Skipping means cannot guarantee integrity, so prevent cache writes in dependents.
                    blockCacheWrite = true;
                    break;
                }
            }
            // Apply status changes to direct dependents
            if (blockCacheWrite) {
                for (const consumer of operation.consumers) {
                    const consumerBuildCacheContext = this._getBuildCacheContextByOperation(consumer);
                    if (consumerBuildCacheContext) {
                        consumerBuildCacheContext.isCacheWriteAllowed = false;
                    }
                }
            }
        });
        hooks.afterExecuteOperations.tapPromise(PLUGIN_NAME, async () => {
            this._buildCacheContextByOperation.clear();
        });
    }
    _getBuildCacheContextByOperation(operation) {
        const buildCacheContext = this._buildCacheContextByOperation.get(operation);
        return buildCacheContext;
    }
    _getBuildCacheContextByOperationOrThrow(operation) {
        const buildCacheContext = this._getBuildCacheContextByOperation(operation);
        if (!buildCacheContext) {
            // This should not happen
            throw new node_core_library_1.InternalError(`Build cache context for operation ${operation.name} should be defined`);
        }
        return buildCacheContext;
    }
    _tryGetProjectBuildCache({ buildCacheConfiguration, buildCacheContext, terminal, record }) {
        var _a;
        if (!buildCacheContext.operationBuildCache) {
            const { cacheDisabledReason } = buildCacheContext;
            if (cacheDisabledReason && !((_a = record.operation.settings) === null || _a === void 0 ? void 0 : _a.allowCobuildWithoutCache)) {
                terminal.writeVerboseLine(cacheDisabledReason);
                return;
            }
            if (!buildCacheConfiguration) {
                // Unreachable, since this will have set `cacheDisabledReason`.
                return;
            }
            // eslint-disable-next-line require-atomic-updates -- This is guaranteed to not be concurrent
            buildCacheContext.operationBuildCache = ProjectBuildCache_1.ProjectBuildCache.forOperation(record, {
                buildCacheConfiguration,
                terminal
            });
        }
        return buildCacheContext.operationBuildCache;
    }
    // Get a ProjectBuildCache only cache/restore log files
    async _tryGetLogOnlyProjectBuildCacheAsync({ buildCacheContext, rushProject, terminal, buildCacheConfiguration, cobuildConfiguration, phase }) {
        if (!(buildCacheConfiguration === null || buildCacheConfiguration === void 0 ? void 0 : buildCacheConfiguration.buildCacheEnabled)) {
            return;
        }
        const { outputFolderNames, stateHash } = buildCacheContext;
        const hasher = crypto.createHash('sha1');
        hasher.update(stateHash);
        if (cobuildConfiguration.cobuildContextId) {
            hasher.update(`\ncobuildContextId=${cobuildConfiguration.cobuildContextId}`);
        }
        hasher.update(`\nlogFilesOnly=1`);
        const operationStateHash = hasher.digest('hex');
        const projectBuildCache = ProjectBuildCache_1.ProjectBuildCache.getProjectBuildCache({
            project: rushProject,
            projectOutputFolderNames: outputFolderNames,
            buildCacheConfiguration,
            terminal,
            operationStateHash,
            phaseName: phase.name
        });
        // eslint-disable-next-line require-atomic-updates -- This is guaranteed to not be concurrent
        buildCacheContext.operationBuildCache = projectBuildCache;
        return projectBuildCache;
    }
    async _tryGetCobuildLockAsync({ cobuildConfiguration, buildCacheContext, projectBuildCache, packageName, phaseName }) {
        if (!buildCacheContext.cobuildLock) {
            if (projectBuildCache && (cobuildConfiguration === null || cobuildConfiguration === void 0 ? void 0 : cobuildConfiguration.cobuildFeatureEnabled)) {
                if (!buildCacheContext.cobuildClusterId) {
                    // This should not happen
                    throw new node_core_library_1.InternalError('Cobuild cluster id is not defined');
                }
                buildCacheContext.cobuildLock = new CobuildLock_1.CobuildLock({
                    cobuildConfiguration,
                    projectBuildCache,
                    cobuildClusterId: buildCacheContext.cobuildClusterId,
                    lockExpireTimeInSeconds: PERIODIC_CALLBACK_INTERVAL_IN_SECONDS * 3,
                    packageName,
                    phaseName
                });
            }
        }
        return buildCacheContext.cobuildLock;
    }
    async _createBuildCacheTerminalAsync({ record, buildCacheContext, buildCacheEnabled, rushProject, logFilenameIdentifier, quietMode, debugMode }) {
        const silent = record.silent;
        if (silent) {
            const nullTerminalProvider = new NullTerminalProvider_1.NullTerminalProvider();
            return new terminal_2.Terminal(nullTerminalProvider);
        }
        let cacheConsoleWritable;
        // This creates the writer, only do this if necessary.
        const collatedWriter = record.collatedWriter;
        const cacheProjectLogWritable = await this._tryGetBuildCacheTerminalWritableAsync({
            buildCacheContext,
            buildCacheEnabled,
            rushProject,
            logFilenameIdentifier
        });
        if (quietMode) {
            const discardTransform = new terminal_1.DiscardStdoutTransform({
                destination: collatedWriter
            });
            const normalizeNewlineTransform = new terminal_1.TextRewriterTransform({
                destination: discardTransform,
                normalizeNewlines: node_core_library_1.NewlineKind.Lf,
                ensureNewlineAtEnd: true
            });
            cacheConsoleWritable = normalizeNewlineTransform;
        }
        else {
            cacheConsoleWritable = collatedWriter;
        }
        let cacheCollatedTerminal;
        if (cacheProjectLogWritable) {
            const cacheSplitterTransform = new terminal_2.SplitterTransform({
                destinations: [cacheConsoleWritable, cacheProjectLogWritable]
            });
            cacheCollatedTerminal = new stream_collator_1.CollatedTerminal(cacheSplitterTransform);
        }
        else {
            cacheCollatedTerminal = new stream_collator_1.CollatedTerminal(cacheConsoleWritable);
        }
        const buildCacheTerminalProvider = new CollatedTerminalProvider_1.CollatedTerminalProvider(cacheCollatedTerminal, {
            debugEnabled: debugMode
        });
        return new terminal_2.Terminal(buildCacheTerminalProvider);
    }
    async _tryGetBuildCacheTerminalWritableAsync({ buildCacheEnabled, rushProject, buildCacheContext, logFilenameIdentifier }) {
        // Only open the *.cache.log file(s) if the cache is enabled.
        if (!buildCacheEnabled) {
            return;
        }
        const logFilePaths = (0, ProjectLogWritable_1.getProjectLogFilePaths)({
            project: rushProject,
            logFilenameIdentifier: `${logFilenameIdentifier}.cache`
        });
        buildCacheContext.buildCacheTerminalWritable = await (0, ProjectLogWritable_1.initializeProjectLogFilesAsync)({
            logFilePaths
        });
        return buildCacheContext.buildCacheTerminalWritable;
    }
}
exports.CacheableOperationPlugin = CacheableOperationPlugin;
function clusterOperations(initialClusters, operationBuildCacheMap) {
    var _a;
    // If disjoint set exists, connect build cache disabled project with its consumers
    for (const [operation, { cacheDisabledReason }] of operationBuildCacheMap) {
        const { associatedProject: project, associatedPhase: phase } = operation;
        if (project && phase) {
            if (cacheDisabledReason && !((_a = operation.settings) === null || _a === void 0 ? void 0 : _a.allowCobuildWithoutCache)) {
                /**
                 * Group the project build cache disabled with its consumers. This won't affect too much in
                 * a monorepo with high build cache coverage.
                 *
                 * The mental model is that if X disables the cache, and Y depends on X, then:
                 *   1. Y must be built by the same VM that build X;
                 *   2. OR, Y must be rebuilt on each VM that needs it.
                 * Approach 1 is probably the better choice.
                 */
                for (const consumer of operation.consumers) {
                    initialClusters === null || initialClusters === void 0 ? void 0 : initialClusters.union(operation, consumer);
                }
            }
        }
    }
}
exports.clusterOperations = clusterOperations;
//# sourceMappingURL=CacheableOperationPlugin.js.map